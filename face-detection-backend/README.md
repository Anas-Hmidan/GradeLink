# Cheating Detection API ðŸ”

A production-ready Flask REST API that detects suspicious behavior during online exams by analyzing video frames. **Screenshots are saved ONLY when suspicious activity is detected**, ensuring privacy and efficient storage.

## ðŸŽ¯ Key Features

- **Privacy-First Design**: Screenshots captured only when cheating is detected
- **Smart Persistence**: Issues must persist 2+ seconds to avoid false positives
- **Rate Limiting**: 5-second cooldown between saves per student
- **Production Logging**: Rotating logs with configurable levels
- **Highly Configurable**: Environment-based configuration
- **Performance Optimized**: Frame processing intervals to reduce CPU load
- **Comprehensive Testing**: Automated test suite validates behavior

## ðŸš€ Quick Start

### Prerequisites

- Python 3.7+
- pip
- Webcam or video source

### Installation

1. **Clone the repository**
   ```bash
   cd face-detection-backend
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   ```

3. **Activate virtual environment**
   ```bash
   # Windows
   venv\Scripts\activate
   
   # Linux/Mac
   source venv/bin/activate
   ```

4. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

5. **Run the API**
   ```bash
   python api.py
   ```

The API will start on `http://localhost:5000`

## ðŸ§ª Testing

Run the comprehensive test suite:

```bash
python scripts\test_api.py
```

This validates:
- âœ… Health check endpoint
- âœ… Normal monitoring (no screenshots)
- âœ… Suspicious activity (screenshots saved)
- âœ… Multiple frames (no spam)
- âœ… Student check endpoint

## ðŸ“š API Documentation

See [API_DOCUMENTATION.md](API_DOCUMENTATION.md) for complete endpoint reference.

### Quick Example

**Analyze a frame:**
```python
import requests
import base64

# Read and encode image
with open('frame.jpg', 'rb') as f:
    frame_b64 = base64.b64encode(f.read()).decode('utf-8')

# Send to API
response = requests.post(
    'http://localhost:5000/analyze-frame',
    json={
        'frame': frame_b64,
        'student_id': 'STUDENT_001'
    }
)

result = response.json()
print(f"Cheating detected: {result['cheating_detected']}")
print(f"Screenshot saved: {result['frame_saved']}")
```

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file (copy from `.env.example`):

```env
# Server
API_HOST=0.0.0.0
API_PORT=5000
DEBUG_MODE=False

# Detection
FACE_VISIBILITY_THRESHOLD=0.7
MIN_SUSPICIOUS_DURATION=2
FRAME_SAVE_COOLDOWN=5

# Performance
FRAME_PROCESS_INTERVAL=1  # 1=all frames, 2=every other
```

### Key Configuration Options

| Parameter | Default | Description |
|-----------|---------|-------------|
| `FACE_VISIBILITY_THRESHOLD` | 0.08 | Minimum 8% face coverage (very lenient) |
| `MIN_SUSPICIOUS_DURATION` | 3s | How long issue must persist |
| `FRAME_SAVE_COOLDOWN` | 5s | Time between saves per student |
| `FRAME_PROCESS_INTERVAL` | 1 | Process every Nth frame |

## ðŸ”’ How Screenshots Work

```python
# This is the critical logic
if result['cheating_detected'] and 'frame' in result:
    # Only save if issue persists AND cooldown passed
    frame_path = save_suspicious_frame(
        result['frame'],
        result['reason'],
        student_id
    )
```

**Screenshots are saved when:**
1. âœ… `cheating_detected` is `True`
2. âœ… Issue persists for 3+ seconds (not a glitch)
3. âœ… Cooldown period has passed (prevents spam)

**Smart Detection Logic:**
- Face coverage >5% AND not at edge = OK (normal behavior)
- This allows students to sit at various distances
- Natural head movements won't trigger alerts

**Detection Reasons:**
- `face_not_detected` - No face visible
- `face_out_of_frame` - Face at frame edges
- `face_partially_visible` - Face coverage < 70%
- `multiple_faces_detected` - Multiple people detected

## ðŸ“Š Monitoring

### View Logs
```bash
# Windows
Get-Content logs\api.log -Wait -Tail 20

# Linux/Mac
tail -f logs/api.log
```

### Check Suspicious Activities
```bash
ls suspicious_frames/STUDENT_001/
```

### Health Check
```bash
curl http://localhost:5000/health
```

## ðŸ—ï¸ Project Structure

```
face-detection-backend/
â”œâ”€â”€ api.py                      # Main Flask application
â”œâ”€â”€ config.py                   # Configuration management
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example               # Environment template
â”œâ”€â”€ .gitignore                 # Git ignore rules
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ API_DOCUMENTATION.md       # Complete API reference
â”œâ”€â”€ IMPROVEMENTS.md            # Enhancement details
â”œâ”€â”€ logs/                      # Log files (auto-created)
â”‚   â””â”€â”€ api.log
â”œâ”€â”€ suspicious_frames/         # Screenshots (ONLY when cheating)
â”‚   â””â”€â”€ STUDENT_001/
â”‚       â”œâ”€â”€ face_not_detected_20251119_103045.jpg
â”‚       â””â”€â”€ multiple_faces_20251119_103150.jpg
â””â”€â”€ scripts/
    â””â”€â”€ test_api.py           # Test suite
```

## ðŸš€ Production Deployment

### Using Gunicorn (Recommended)

1. **Install gunicorn:**
   ```bash
   pip install gunicorn
   ```

2. **Run with multiple workers:**
   ```bash
   gunicorn -w 4 -b 0.0.0.0:5000 --timeout 120 api:app
   ```

### Using Docker

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:5000", "api:app"]
```

### Environment Configuration

**Development:**
```env
DEBUG_MODE=True
LOG_LEVEL=DEBUG
FRAME_PROCESS_INTERVAL=1
```

**Production:**
```env
DEBUG_MODE=False
LOG_LEVEL=WARNING
FRAME_PROCESS_INTERVAL=2
ALLOWED_ORIGINS=https://yourdomain.com
```

## ðŸ”§ Troubleshooting

### API won't start
- Check if port 5000 is available
- Verify Python version (3.7+)
- Check logs in `logs/api.log`

### Face detection not working
- Ensure OpenCV is properly installed
- Check lighting conditions
- Verify webcam permissions

### Screenshots not saving
- Check `suspicious_frames/` directory permissions
- Review logs for errors
- Verify issue persists for 2+ seconds

## ðŸ“ˆ Performance Tuning

### Reduce CPU usage:
```env
FRAME_PROCESS_INTERVAL=2  # Process every other frame
```

### Adjust detection sensitivity:
```env
FACE_VISIBILITY_THRESHOLD=0.6  # More lenient (60%)
MIN_SUSPICIOUS_DURATION=3      # Wait longer (3s)
```

### Increase rate limiting:
```env
FRAME_SAVE_COOLDOWN=10  # 10 seconds between saves
```

## ðŸ¤ Integration Examples

### React/JavaScript
```javascript
async function analyzeFrame(canvas, studentId) {
  const frameData = canvas.toDataURL('image/jpeg').split(',')[1];
  
  const response = await fetch('http://localhost:5000/analyze-frame', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      frame: frameData,
      student_id: studentId
    })
  });
  
  return await response.json();
}
```

### Python
```python
import cv2
import base64
import requests

cap = cv2.VideoCapture(0)
ret, frame = cap.read()

_, buffer = cv2.imencode('.jpg', frame)
frame_b64 = base64.b64encode(buffer).decode('utf-8')

response = requests.post(
    'http://localhost:5000/analyze-frame',
    json={'frame': frame_b64, 'student_id': 'STU001'}
)
```

## ðŸ“ License

MIT License - See LICENSE file for details

## ðŸ™ Acknowledgments

- OpenCV for face detection
- Flask for web framework
- All contributors and testers

## ðŸ“§ Support

For issues or questions, please create an issue in the repository.

---

**Made with â¤ï¸ for academic integrity**
